# Methodology {#methodology}

_Need to broadly describe different approaches - it may be better to introduce ARIMA first then introduce AR, MA and random walks as special cases of ARIMA. These models will be restated (with model parameters) in results chapters_

This chapter gives a broad introduction to the nature and origin of our data, and the methods used in order to model hot water electricity demand.
<!-- Required to number equations in HTML files 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
-->
```{r loadDTandpc_rm, include=FALSE}
# This loads percentage of data removed
load(paste0(dFile, "pc_rm"))
load(paste0(dFile, "DT.Rda"))
```

## Data background

The data used for this analysis was collected from monitoring the submetered electrical power usage of 44 households in Hawkes Bay and Taranaki, New Zealand, at one minute intervals between 2014 and 2018 as part of the GREEN Grid project[@GREENGrid]. It is publically available from the UK Data Service. More information about this dataset, including detailed reports of data issues, the cleaning process, and access instructions, is available at https://cfsotago.github.io/GREENGridData/.

```{r headDT, include=FALSE, fig.cap="Example of the clean and processed data used in the analysis"}
knitr::kable(head(DT))
```

The data was cleaned and wrangled until it was in the format shown in Table \@ref(tab:headDT). The columns included are `linkID`, representing the household, `r_dateTime`, which is `R`'s internal datetime format, `dateTime_nz`, the actual local datetime, and `HWelec` and `nonHWelec`, the average hot water electricity and non hot water electricity used over the time steps in the data (original 1 minute shown).
For our half hour analysis, a new dataframe was constructed whereby the electricity power was averaged over each half hour time step.


As we are concerned with predictability and patterns within our data over time, we must utilise time series data analysis methods. The book "Introductory Time Series With R"[@Cowpertwait2009] was used extensively to inform the overall process.
All data processing and modelling was conducted using the `R` programming language, and significant consideration has been given to facilitating reproducibility of results. The code is publically available under an Apache License (version 2.0) at https://github.com/raffertyparker/HWCanalysis. _it's not yet, but will be_

## Time series overview and notation

From [@Cowpertwait2009], a time series $\{x_1, x_2, ..., x_n\}$, also abbreviated to $\{x_t\}$, is a collection of $n$ samples of data taken at discrete times $\{t = 1,2,...,n\}$. Statistical models may be built to fit this data, providing the ability to predict a future value based on historical values. Models are denoted using the 'hat' notation, where $\{\hat x_t\}$ is the model of $\{x_t\}$. A prediction at time $t$ of a value $k$ steps forward is denoted $\{\hat x_{t+k | t}\}$.

The difference between an observed value and the value predicted by the model is known as the _residual_. Most models are fitted to the data such that the model minimises the sum of the square of each residual (referred to as RSS, residual sum of squares). Models that are advanced enough to effectively take into consideration data attributes such as trend and cyclic (known as 'seasonal') effects should have a residual time series that appromiates _white noise_, where a white noise time series, $\{w_t : t = 1,2,...,n\}$ is a set of independent and identically distributed variables with zero mean. 

The mean of a sample is denoted with an overline, such that

\begin{equation}
\overline x = \sum x_i/n
\end{equation}

Many mathematical descriptions of predictive models utilise an operator $B$, known as the 'backward shift' or 'lag' operator, where 
\begin{equation}
Bx_t = x_{t-1}
\end{equation}. 

Data can be thought to be made up of dependent and independent (or 'explanatory') variables. Broadly speaking, dependent variables are those we are interested in measuring or predicting (in this research, hot water electricity demand). Explanatory variables are those we expect to impact our dependent variables (in this research, time and non hot-water electricity demand). 

## Introduction to methods and models

This section outlines a broad introduction to the various models used either implicitly or explicitly in this analysis. Refer to [@Cowpertwait2009] for further information.

### Random walk

A time series $\{x_t\}$ is known as a 'random walk' if 

\begin{equation}
x_t = x_{t+1} + w_t
(\#eq:randomWalk)
\end{equation}
where $\{w_t\}$ is a white noise series. 
This model assumes (provided $\{\overline w_t\} = 0$) that hot water electricity demand of the next timestep can be best predicted by the demand of the current timestep.

### Simple linear regression

Simple linear regression is a common forecasting model prized for its simplicity in interpretation and computation.
More generally, a linear model for time series $\{x_t:t = 1,...,n\}$ is expressed using the formula
\begin{equation}
x_t = \alpha_0 + \alpha_1u_{1,t} + \alpha_2u_{2,t} + ... + \alpha_mu_{m,t} + z_t
(\#eq:linearModel)
\end{equation}
where $u_{i,t}$ is the value of the $i$th explanatory variable at time $t$, $z_t$ is the error at time $t$, and $\alpha_0, \alpha_1, ... , \alpha_n$ are model parameters, which are fitted to the dataset by minimising the RSS. For this more general method, values of $u_{i,t}$ may take polynomial values, for example $u_{i,t} = t^i$.
A special case of a linear model is the simple linear regression, which is represented by a straight line. Thus equation \@ref(eq:linearModel) becomes
\begin{equation}
x_t = \alpha_0 + \alpha_1 t
(\#eq:simpleLinearRegression)
\end{equation}

For time-series forecasting, linear regression uses time as the independent (or 'explanatory') variable, with the value to be predicted (such as electricity demand) as the dependent (or 'response') variable.  _show figure demonstrating?_

### Moving average

A q-order moving average process, $MA(q)$ is defined as
\begin{equation}
x_t = w_t + \beta_1 w_{t-1} + ... + \beta_q w_{t-q}
(\#eq:MA)
\end{equation}
where $\{w_t\}$ is white noise with zero mean and variance $\sigma^2_w$. Equation \@ref(MA1) can be written in terms of the backshift operator $B$ as
\begin{equation}
x_t = (1 + \beta_1 B + \beta_2 B^2 + ... + \beta_q B^q)w_t = \phi_qBw_t
\end{equation}
where $\phi_q$ is a polynomial of order 2.

### Autoregression

A time series $x_t$ is an autoregressive process of order $p$ (referred to as $AR(p)$) if it can be represented as
\begin{equation}
x_t = \alpha_1x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p} + w_t
(\#eq:AR)
\end{equation}

where $\{w_t\}$ is white noise and $\alpha_i$ are model parameters, $\alpha_p \neq 0$.

A prediction is then given by

\begin{equation}
\hat x_{t} = \alpha_1 x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p}
(\#eq:ARmodel)
\end{equation}.

### Integrated model

Differencing a time series $\{x_t\}$ is a method of removing trends, where, for example with a random walk process, the difference is white noise $x_t - x_{t-1} = w_t$.
More generally, a time series $\{x_t\}$ is referred to as _integrated_ of order $d$ (denoted $I(d)$) if the $d$th difference of $\{x_t\}$ is white noise.
_elaborate this slightly_
The random walk model is the special case $I(1)$.

### ARIMA

An Autoregressive Moving Average (ARMA) process of order $(p,q)$ combines autoregression with the moving average process, adding the two together in the form 
\begin{equation}
x_t = \alpha_1 x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p} + w_t + \beta_1 w_{t-1} + \beta_2 w_{t-2} + ... + \beta_q w_{t-q}
(\#eq:ARMA)
\end{equation}
This may be expressed in terms of the backward shift operator in polynomial form
\begin{equation}
\theta (B) x_t = \phi (B) w_t
(\#eq:ARMApolyform)
\end{equation}
The three previously described processes are frequently combined into what as known as an Autoregressive Integrated Moving Average.
A time series $\{x_t\}$ is referred to as an $ARIMA(p,d,q)$ process if, when differenced $d$ times, it becomes an $ARMA(p,q)$ process.
In a similar manner to how trends can be removed through differencing at lag 1, seasonal effects within data (such as daily use patterns) can be removed by differencing at lag $s$, where $s$ is the length of the season.
A seasonal ARIMA model may also introduce additional autoregressive and moving average terms at lag $s$, giving a model of the form $ARIMA(p,d,q)(P,D,Q)_s$, expressed using the backward shift operator as
\begin{equation}
$\Theta_P(B^s)\theta_p(B)(1-B^s)^D(1-B)^d x_t = \Phi_Q(B^s)\phi_q(B)w_t$
\end{equation}

### VAR

Vector Autoregression (VAR) is a model that utilises the same predictive method as the ARIMA model, with the addition of a seperate predictive variable. For this research, our additional variable is all other electricity use. We may reasonably assume that for many houses, the consumption of hot water use would correspond closely to other electricity use. The more obvious example is that electricity use, with the exception of thermostatic electric heating and appliances set to timers, would tend not to occur when residents are away from home or sleeping. In addition, we may expect hot water electricity use to lag (or lead) other electricity use. Consider a resident waking up, putting down some toast and boiling the kettle, then getting into the shower.
Our VAR model hopes to capture the relationship between hot water use and other electricity use in order to provide additional accuracy to the ARIMA model.

### Logistic regression

The models previously mentioned assume the dependent variables are continuous and have no limits on them. In particular, while being fit to simply minimise the RSS, they may predict values that are greater than the maximum element power or less than zero, and series' of values that are 'smoother' than the original data. 
This is particularly pronounced when considering data at 1 minute resolution. At this timescale, the true nature of the hot water element as an "on/off" device becomes apparent (show figure).

### Generalised additive models

Generalised additive models goes here

## Metrics

Each model will be compared against one another using a number of relevent metrics. 

### Accuracy

This is determined by the root mean square (RMS) of the residuals, averaged over each house, with lower values indicating higher accuracy.

### Physical fidelity

In addition to accuracy of prediction values, there are benefits to models that closely resemble the physical process they are predicting.  While a model that provides occasional values that are negative or greater than the element can output may provide a minimal RSS, they would be less than ideal to use when modelling for research purposes. 
Physical fidelity is a measure of how closely the model approximates the physical process of the element of the hot water cylinder turning on and off in response to the draw down of hot water. Properties of decent physical fidelity include the non-existance of negative values or values above the maximum power of the element being modelled, and replication of the "on/off" nature of the element at one minute timescales.

### Interpretability

Another important consideration for research purposes is interpretation of results. Model interpretability is a measure of how well we can infer fundamental behavioural properties (cycles, trends, correllations) from the model. Models that are easy to interpret are valuable for understanding the human behaviour behind hot water use, as well as for building simulations for further research.
For a model to score highly in this metric, its parameters need to be easily obtainable, and preferably composed of succinct equations. 
Models that simply output large matrices score less highly.

### Computational efficiency

For research purposes, the computational expense of modelling the electricity demand of a small number of households isn't of much concern. More computationally expensive models can be run overnight, and outputs need only be obtained once in order to conduct analysis on them.
When considering industry use however, computational efficiency becomes much more important.
In order to make the real-time predictions necessary to effectively participate in demand response markets, models for thousands, or even hundreds of thousands of households need to be updated at least half-hourly, potentially more often, with reasonable speed. 
In addition to processing expense, the amount of storage space each model requires is also worth consideration when considering large numbers of households.
