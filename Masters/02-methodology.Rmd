# Methodology {#methodology}

_Need to broadly describe different approaches - it may be better to introduce ARIMA first then introduce AR, MA and random walks as special cases of ARIMA. These models will be restated (with model parameters) in results chapters_

This chapter begins by giving a broad introduction to the origin of our dataset, as well as noting some necessary preliminary cleaning. It goes on to provide a more theoretical background as to the nature of our data. Mathematical descriptions of the methods and models utilised in the main body of work are then introduced, with applicability to our context provided. Finally, the metrics by which the models are compared with one another are outlined.

<!-- Required to number equations in HTML files 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
-->
```{r loadDTandpc_rm, include=FALSE}
# This loads percentage of data removed
load(paste0(dFile, "pc_rm"))
load(paste0(dFile, "DT.Rda"))
```

## Data background

The data used for this analysis was collected from monitoring the submetered electrical power usage of 44 households in Hawkes Bay and Taranaki, New Zealand, at one minute intervals between 2014 and 2018 as part of the GREEN Grid project[@GREENGrid]. This dataset is publically available from the UK Data Service. Publications to date that have utilised the dataset include [@Ocampo2015], [@Suomalainen2017], [@Stephenson2018], [@JackKiti2018], and [@JackDew2018]. More information about this dataset, including detailed reports of data issues, the cleaning process, and access instructions, is available at https://cfsotago.github.io/GREENGridData/. 
_MISSING DATA: explain what steps were taken (or not taken) to deal with holes in data. Reference other work if possible. Start by finding how much is missing as a percentage by calculating actual number of data between start date and end date divided by expected number._

```{r headDT, include=FALSE, fig.cap="Example of the clean and processed data used in the analysis"}
knitr::kable(head(DT))
```

For the purposes of the current project, the data was cleaned and processed until it was in the format shown in Table (\#tab:headDT). The columns included are `linkID`, representing the household, `r_dateTime`, which is `R`'s internal datetime format, `dateTime_nz`, the local (New Zealand) datetime, and `HWelec` and `nonHWelec`, the average hot water electricity and non hot water electricity used over the time steps in the data.
Chapter \@ref(half-hour) is concerned with constructing models that accurately represent the data storage and transmission characteristics of current smart meters in New Zealand, in particular by using electricity demand data that has been averaged over half hour intervals. For this analysis, a new dataframe was constructed whereby the electricity power was averaged over each half hour time step.

As this work is focussed on forecasting hot water electricity usage, we are concerned with predictability and patterns within our data over time, thus we utilise time series data analysis methods. The book "Introductory Time Series With R"[@Cowpertwait2009] was used extensively to inform the overall process.
All data processing and modelling was conducted using the `R` programming language, and significant consideration has been given to facilitating reproducibility of results. The code is publically available under an Apache License (version 2.0) at https://github.com/raffertyparker/HWCanalysis. _it's not yet, but will be_

## Time series overview and notation

A time series $\{x_1, x_2, ..., x_n\}$, also abbreviated to $\{x_t\}$, is a collection of $n$ samples of data taken at discrete times $\{t = 1,2,...,n\}$ [@Cowpertwait2009]. Statistical models may be built to fit this data, providing the ability to predict a future value based on historical values. Models are denoted using the 'hat' notation, where $\{\hat x_t\}$ is the model of $\{x_t\}$.  A prediction at time $t$ of a value $k$ steps forward is denoted $\{\hat x_{t+k | t}\}$ _May not be necessary to include if we only consider k = 1_.
The difference between an observed value and the value predicted by the model is known as the _residual_. 

Data can be thought to be made up of dependent and independent (or 'explanatory') variables. Broadly speaking, dependent variables are those we are interested in measuring or predicting (in this research, hot water electricity demand). Explanatory variables are those we expect to impact our dependent variables (in this research, time and the electricity demand of other appliances). 

## Introduction to methods and models

This section outlines a broad introduction to the various models used either implicitly or explicitly in this analysis. Refer to [@Cowpertwait2009] for further information.

### Naive model

A time series $\{x_t\}$ is known as a 'random walk' if 

\begin{equation}
x_t = x_{t+1} + w_t
(\#eq:randomWalk)
\end{equation}
where $\{w_t\}$ is a white noise series. 
Random walk models are more commonly used in simulations. When used in simulations, a random walk model will artificially generate white noise to simulate a potential evolution of the variable in time.
Due to their simplicity and ease of computation they are sometimes used in forecasting as a 'benchmark' model, by which other models may be compared. For this reason, they are referred to as 'naive' models.
When used for forecasting, this model assumes that the mean of the white noise is equal to zero, ($\{\overline w_t\} = 0$), and consequently that the dependant variable (hot water electricity demand, in our case) of the next timestep can be best predicted by the demand of the current timestep. 
_show figure demonstrating_

### Simple linear regression

Simple linear regression is a common forecasting model prized for its simplicity in interpretation and computation.
A special case of a linear model is the simple linear regression, which is represented by a straight line. This is represented by the equation
\begin{equation}
x_t = \alpha_0 + \alpha_1 t
(\#eq:simpleLinearRegression)
\end{equation}

For time-series forecasting, simple linear regression can fit a line to historical values of the dependent (or 'response') variable in order to predict future values. While this useful for determining general trends over time, they cannot capture any regular shorter term fluctuations of time series data (referred to as 'seasonality'). 
Another way of utilising simple linear regression for forecasting is by introducing a seperate predictor variable. For our data, we seperate electricity demand into hot water, and other appliances. Simple linear regression is a foundational method of exploring how the demand of other appliances at time $t$ can be used to predict hot water electricity demand at a time $t + k$.
_show figure demonstrating?_

### Moving average

A q-order moving average process, $MA(q)$ is defined as
\begin{equation}
x_t = w_t + \beta_1 w_{t-1} + ... + \beta_q w_{t-q}
(\#eq:MA1)
\end{equation}
where $\{w_t\}$ is white noise with zero mean and variance $\sigma^2_w$. Equation \@ref(eq:MA1) can be expressed as
\begin{equation}
x_t = (1 + \beta_1 B + \beta_2 B^2 + ... + \beta_q B^q)w_t = \phi_qBw_t
\end{equation}
where $B$ is the backshift operator, $Bx_t = x_{t-1}$, and $\phi_q$ is a polynomial of order 2.

### Autoregression

A time series $x_t$ is an autoregressive process of order $p$ (referred to as $AR(p)$) if it can be represented as
\begin{equation}
x_t = \alpha_1x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p} + w_t
(\#eq:AR)
\end{equation}

where $\{w_t\}$ is white noise and $\alpha_i$ are model parameters, $\alpha_p \neq 0$.

A prediction is then given by

\begin{equation}
\hat x_{t} = \alpha_1 x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p}
(\#eq:ARmodel)
\end{equation}.

### Integrated model

Differencing a time series $\{x_t\}$ is a method of removing trends, where, for example with a random walk process, the difference is white noise $x_t - x_{t-1} = w_t$.
More generally, a time series $\{x_t\}$ is referred to as _integrated_ of order $d$ (denoted $I(d)$) if the $d$th difference of $\{x_t\}$ is white noise.
_elaborate on this slightly_.
The random walk model is the special case $I(1)$.

### ARIMA
_Perhaps abandon IMA part and just do seasonal AR_
An Autoregressive Moving Average (ARMA) process of order $(p,q)$ combines autoregression with the moving average process, adding the two together in the form 
\begin{equation}
x_t = \alpha_1 x_{t-1} + \alpha_2 x_{t-2} + ... + \alpha_p x_{t-p} + w_t + \beta_1 w_{t-1} + \beta_2 w_{t-2} + ... + \beta_q w_{t-q}
(\#eq:ARMA)
\end{equation}
This may be expressed in terms of the backward shift operator in polynomial form
\begin{equation}
\theta (B) x_t = \phi (B) w_t
(\#eq:ARMApolyform)
\end{equation}
The previously described processes are frequently combined into what as known as an Autoregressive Integrated Moving Average.
A time series $\{x_t\}$ is referred to as an $ARIMA(p,d,q)$ process if, when differenced $d$ times, it becomes an $ARMA(p,q)$ process.
In a similar manner to how trends can be removed through differencing at lag 1, seasonal effects within data (such as daily use patterns) can be removed by differencing at lag $s$, where $s$ is the length of the season.
A seasonal ARIMA model may also introduce additional autoregressive and moving average terms at lag $s$, giving a model of the form $ARIMA(p,d,q)(P,D,Q)_s$, expressed using the backward shift operator as
\begin{equation}
\Theta_P(B^s)\theta_p(B)(1-B^s)^D(1-B)^d x_t = \Phi_Q(B^s)\phi_q(B)w_t
\end{equation}

### VAR

Vector Autoregression (VAR) is a model that utilises the same predictive method as the ARIMA model, with the addition of (at least) one additional variable. 
This gives two time series', $\{x_t\}$ and $\{y_t\}$, which, for a VAR(1) process, can be expressed as
\begin{equation}
    x_t = \theta_{11}x_{t-1} + \theta_{12}y_{t-1} + w_{x,t}
    (\#eq:VAR1)
\end{equation}
\begin{equation}
    y_t = \theta_{21}x_{t-1} + \theta_{22}y_{t-1} + w_{y,t}
    (\#eq:VAR2)
\end{equation}

where $\{w_{x,t}\}$ and $\{w_{y,t}\}$ are bivariate white noise and $\phi_{i,j}$ are model parameters.

Using matrix notation, equations \@ref(eq:VAR1) and \@ref(eq:VAR2) can be written as
\begin{equation}
\bf{Z}_t = \bf{\Theta}\bf{Z}_{t-1} + \bf{w}_t
(\#eq:VAR)
\end{equation}
where 
\begin{equation*}
    \bf{Z}_t = \begin{pmatrix}x_t \\ y_t \end{pmatrix}
\end{equation*}
\begin{equation*}
\bf{\Theta} = \begin{pmatrix}\theta_{11} & \theta_{12}\\ \theta_{21} & \theta_{22}\end{pmatrix}
\end{equation*}
and
\begin{equation*}
\bf{w}_t = \begin{pmatrix}w_{x,t} \\ w_{y,t}\end{pmatrix}
\end{equation*}.

Equation \@ref(eq:VAR) can be expressed using the backshift operator as 
\begin{equation}
(\bf{I} - \bf{\Theta}B)\bf{Z}_t = \bf{\Phi}(B)\bf{Z}_{t} + \bf{w}_t
(\#eq:VARbs)
\end{equation}

where $\bf{\Phi}$ is a matrix polynomial of order 1 and $\bf{I}$ is a 2 x 2 identity matrix.

For this research, our additional variable is all other electricity use. We may reasonably assume that for many houses, the consumption of hot water use would correspond closely to other electricity use. The more obvious example is that electricity use, with the exception of thermostatic electric heating and appliances set to timers, would tend not to occur when residents are away from home or sleeping. In addition, we may expect hot water electricity use to lag (or lead) other electricity use. Consider a resident waking up, putting down some toast and boiling the kettle, then getting into the shower.
Our VAR model hopes to capture the relationship between hot water use and other electricity use in order to provide additional accuracy to the ARIMA model.

### Logistic regression

The models previously mentioned assume the dependent variables are continuous and have no upper or lower bounds. In particular, while being fit to simply minimise the RSS, they may predict values that are greater than the maximum element power or less than zero, and series' of values that are 'smoother' than the original data. 
This is particularly pronounced when considering data at 1 minute resolution. At this timescale, the true nature of the hot water element as an "on/off" device becomes apparent. See Figure \@ref(fig:elementPlot) for an example of this behaviour.

```{r elementPlot, echo=FALSE, out.width='100%', fig.cap="Hot water electricity use over a day for one household"}
knitr::include_graphics(paste0(pFile, "oneDay.pdf"))
```

### Generalised additive models

Generalised additive models goes here

## Metrics

Each model will be compared against one another using the following metrics. 

### Accuracy

This is determined by the root mean square (RMS) of the residuals, averaged over each house, with lower values indicating higher accuracy.

### Physical fidelity

In addition to accuracy of prediction values, there are benefits to models that closely resemble the physical process they are predicting.  While a model that provides occasional values that are negative or greater than the element can output may provide a minimal RSS, they would not be optimal to use when modelling for research purposes. 
Physical fidelity is a measure of how closely the model approximates the physical process of the element of the hot water cylinder turning on and off in response to the draw down of hot water. Properties of decent physical fidelity include the non-existance of negative values or values above the maximum power of the element being modelled, and replication of the on/off nature of the element at one minute timescales.

### Interpretability

Another important consideration for research purposes is interpretation of results. Model interpretability is a measure of how well we can infer fundamental behavioural properties (cycles, trends, correllations) from the model. Models that are easy to interpret are valuable for understanding the human behaviour behind hot water use, as well as for building simulations for further research.
For a model to score highly in this metric, its parameters need to be easily obtainable, and preferably composed of succinct equations. 
Models that simply output large matrices score poorly.

### Computational efficiency

For research purposes, the computational expense of modelling the electricity demand of a small number of households isn't of much concern. 
When considering industry use however, computational efficiency becomes much more important.
In order to make the real-time predictions necessary to effectively participate in demand response markets, models for thousands, or even hundreds of thousands of households need to be updated at least half-hourly, potentially more often, with reasonable speed. 
In addition to processing expense, the amount of storage space each model requires is also worth consideration when considering large numbers of households.
